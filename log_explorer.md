

# 🚀 GCP Cloud Logging - Practice Guide

Google Cloud Logging provides powerful tools to **collect, store, analyze, and export logs** generated by your GCP resources.

---

## 🔍 1. **Logs Explorer**

* The **main UI tool** in GCP for viewing and querying logs.
* Navigate to: **Logging > Logs Explorer**
* Features:

  * Filter logs by **timestamp, severity, resource type, label**, and **text search**.
  * Use **Logging Query Language** (LQL) for advanced filtering:

    ```sql
    resource.type="gce_instance"
    severity="ERROR"
    logName:"/logs/compute.googleapis.com%2Factivity_log"
    ```
  * Save common queries using **Saved Views** for quick access.

✅ *Use Case:* Troubleshooting application errors, monitoring specific VM logs.

---

## 🔄 2. **Log Router**

* **Responsible for routing** incoming logs to appropriate destinations.
* Logs are evaluated against:

  * **Inclusion filters**: What logs to send.
  * **Exclusion filters**: What logs to skip (helps reduce cost).
* Can route to **Cloud Storage**, **BigQuery**, **Pub/Sub**, or **Cloud Logging (default)**.

---

## 📤 3. **Log Sinks**

* **Log Sinks** define where your logs go beyond Cloud Logging.
* Can export logs to:

  * **Cloud Storage** → for **archival**
  * **BigQuery** → for **advanced analytics**
  * **Pub/Sub** → for **streaming real-time log events**

### CLI Example:

```bash
gcloud logging sinks create my-sink storage.googleapis.com/my-logging-bucket \
  --log-filter='severity>=ERROR'
```

💡 *Pro Tip:* Use BigQuery sinks for long-term storage and querying via SQL.

---

## 📈 4. **Log-based Metrics**

* Extract **custom metrics** from logs for monitoring and alerting.
* Two types:

  * **Counter**: Count log entries that match a filter.
  * **Distribution**: Measure values (e.g., response time, latency).

### Example:

Count all ERROR logs from Compute Engine:

```plaintext
resource.type="gce_instance"
severity="ERROR"
```

* Use metrics in **Cloud Monitoring Dashboards** or **Alerting Policies**.

---

## 🕵️‍♂️ 5. **Audit Logs**

GCP **automatically logs admin and access activities**.

| Type               | Description                              |
| ------------------ | ---------------------------------------- |
| **Admin Activity** | Logs configuration changes (always on)   |
| **Data Access**    | Logs read/write access (needs enabling)  |
| **System Events**  | GCP internal operations (always on)      |
| **Policy Denied**  | IAM policy failures / permission denials |

📌 *Retention:* 30 days (by default), viewable via Logs Explorer.

🔐 *Note:* Enable **Data Access Logs** for detailed security auditing.

---

## 🚨 6. **Alerting with Logs**

You can create alerts based on **log-based metrics** to notify on unusual events.

### Steps:

1. Create a **log-based metric** (e.g., count 500 errors).
2. Go to **Monitoring > Alerting > Create Policy**.
3. Define:

   * **Conditions** (e.g., more than 10 errors in 1 minute).
   * **Notification channels** (email, SMS, Slack, etc.).

💬 *Example:* Alert if VM logs show more than 5 critical errors in a minute.

---

## ⚙️ 7. Additional Best Practices

* 🧹 **Use Exclusion Filters** to reduce log volume and cost.
* 🗃️ **Use Log Buckets** for **region-specific storage** and **custom retention periods**.
* 🧪 **Test Queries** in Logs Explorer before using them in sinks or metrics.
* 🔐 **Restrict access** to logs via IAM roles like:

  * `roles/logging.viewer`
  * `roles/logging.admin`
* 📆 **Extend retention** using custom log buckets if needed.

---

## ✅ Summary Cheat Sheet

| Feature           | Purpose                                    |
| ----------------- | ------------------------------------------ |
| Logs Explorer     | View & search logs                         |
| Log Router        | Direct logs to destinations                |
| Log Sinks         | Export logs to Storage / BigQuery / PubSub |
| Log-based Metrics | Custom metrics from logs                   |
| Audit Logs        | Track GCP usage and policy enforcement     |
| Alerting          | Get notified of specific log patterns      |

---

